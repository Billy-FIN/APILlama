{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a method to compare the similarity of the Json output between Llama 3, Llama 3 - one shot, GPT 3.5, and my model while dealing with API endpoints IE (information extraction) task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the same test/eval data while in training\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('billyfin/doc2json')\n",
    "# delete the last line for future one-shot test\n",
    "one_shot_example = dataset['train'][166]\n",
    "dataset = dataset.filter(lambda example, idx: idx != 166, with_indices=True)\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"title\": \"MyIP.com JSON API Documentation\",\n",
      "    \"endpoints\": [\n",
      "        {\n",
      "            \"name\": \"Get IP Information\",\n",
      "            \"description\": \"Retrieves information about the IP address making the request.\",\n",
      "            \"method\": \"GET\",\n",
      "            \"url\": \"https://api.myip.com\",\n",
      "            \"headers\": [],\n",
      "            \"required_parameters\": [],\n",
      "            \"optional_parameters\": []\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "JSON API | MyIP.com JSON API Contact JSON API You can make automated requests to the site using the API . Access URL: https://api.myip.com Response example: {\"ip\":\"66.249.75.9\",\"country\":\"United States\",\"cc\":\"US\"} Response elements: ip: IP address country: IP country location in English language cc: Two-letter country code in ISO 3166-1 alpha-2 format If there is no location data for an IP address cc will return \"XX\" and country \"Unknown\". Is this a free service? Yes. What are the API usage limits? There is no request limit, the only restriction is the server capacity which I will try to keep running smoothly. Can I use it for my commercial application? Yes, please give credit to myip.com if you can. How can I exclude some parameter(s) from the response? I will add that feature shortly, please check back for updates. I want you to add some feature, how can I contact you? If you have a suggestion please contact me here. MyIP.com 2024. × Contact For inquiries or feedback please get in touch at: OK\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset['json_form'][0])\n",
    "print(test_dataset['text_content'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df1b1ad062d4e7da77945e1e7bd9d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoModel, AutoTokenizer, default_data_collator, get_linear_schedule_with_warmup, BitsAndBytesConfig\n",
    "from huggingface_hub import notebook_login\n",
    "from peft import get_peft_config, get_peft_model, PromptTuningInit, PromptTuningConfig, TaskType, PeftType, PeftModel, PeftConfig\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "torch.manual_seed(42)\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 3 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc70d8cc6a940cd93c98f066cf2c9db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"quantization_config\": quantization_config},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "terminators = [\n",
    "    pipeline.tokenizer.eos_token_id,\n",
    "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "count = 1\n",
    "for test_sample in test_dataset['text_content']:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You will be given an API documentation. Extract the endpoints and output in JSON format.\"},\n",
    "        {\"role\": \"user\", \"content\": \"API text content: \" + test_sample + \"\\n\\nJson: \"},\n",
    "    ]\n",
    "    outputs = pipeline(\n",
    "        messages,\n",
    "        max_new_tokens=1024,\n",
    "        eos_token_id=terminators,\n",
    "        do_sample=True,\n",
    "        temperature=0.1,\n",
    "        return_full_text=False,\n",
    "    )\n",
    "    \n",
    "    result = outputs[0][\"generated_text\"]\n",
    "    with open(\"./model_outputs/llama3/\" + str(count) + \".txt\", 'w') as file:\n",
    "        file.write(result)\n",
    "    \n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 3 - one shot outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"quantization_config\": quantization_config},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "terminators = [\n",
    "    pipeline.tokenizer.eos_token_id,\n",
    "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "count = 1\n",
    "for test_sample in test_dataset['text_content']:\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": \"You will be given an API documentation. Extract the endpoints and output in JSON format.\\n\\nAPI text content: \" + one_shot_example['text_content'] + \"\\n\\nJson: \"},\n",
    "        {\"role\": \"assistant\", \"content\": one_shot_example['json_form']},\n",
    "        {\"role\": \"user\", \"content\": \"You will be given an API documentation. Extract the endpoints and output in JSON format.\\n\\nAPI text content: \" + test_sample + \"\\n\\nJson: \"},\n",
    "    ]\n",
    "    outputs = pipeline(\n",
    "        messages,\n",
    "        max_new_tokens=1024,\n",
    "        eos_token_id=terminators,\n",
    "        do_sample=True,\n",
    "        temperature=0.1,\n",
    "        return_full_text=False,\n",
    "    )\n",
    "    \n",
    "    result = outputs[0][\"generated_text\"]\n",
    "    with open(\"./model_outputs/llama3_one_shot/\" + str(count) + \".txt\", 'w') as file:\n",
    "        file.write(result)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT3.5 - one shot outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please type in your api key:  sk-None-LBwUJe7KgakZQCd1sFS2T3BlbkFJGZlBKtOqC13W19K504OG\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "OPENAI_API_KEY = str(input('Please type in your api key: '))\n",
    "\n",
    "count = 1\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "for test_sample in test_dataset['text_content']:\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        # model=\"gpt-4-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"You will be given an API documentation. Extract the endpoints and output in JSON format.\\n\\nAPI text content: \" + one_shot_example['text_content'] + \"\\n\\nJson: \"},\n",
    "            {\"role\": \"assistant\", \"content\": one_shot_example['json_form']},\n",
    "            {\"role\": \"user\", \"content\": \"You will be given an API documentation. Extract the endpoints and output in JSON format.\\n\\nAPI text content: \" + test_sample + \"\\n\\nJson: \"},\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    result = str(completion.choices[0].message.content)\n",
    "    with open(\"./model_outputs/gpt3.5_one_shot/\" + str(count) + \".txt\", 'w') as file:\n",
    "        file.write(result)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n",
      "Current CUDA Device: NVIDIA L40\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "    current_device = torch.cuda.current_device()\n",
    "    device_name = torch.cuda.get_device_name(current_device)\n",
    "    print(\"Current CUDA Device:\", device_name)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, using CPU instead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a75a2dcb0e7f40c4b2020fc60aa73e45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/585 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a375c334bc4bce9f7609f8096321a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6bb1f24452342b38b0abee42c50f38f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/328k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "peft_model_id = \"billyfin/llama_3_prompt_tuning_api2json_v4\"\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path,\n",
    "                                             quantization_config=quantization_config,\n",
    "                                             low_cpu_mem_usage=True,\n",
    "                                            )\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('meta-llama/Meta-Llama-3-8B-Instruct')\n",
    "\n",
    "# set pad_token_id equal to the eos_token_id if not set\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 10240\n",
    "\n",
    "def format(example):\n",
    "    input_messages = [\n",
    "        {\"role\":\"user\", \"content\": one_shot_example['text_content']},\n",
    "        {\"role\":\"assistant\", \"content\": one_shot_example['json_form']},\n",
    "        {\"role\":\"user\", \"content\": example},\n",
    "    ]\n",
    "    example = tokenizer.apply_chat_template(input_messages, tokenize=False) + \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
    "    return example\n",
    "    \n",
    "def preprocess_for_inference(examples):\n",
    "    inputs = f\"{examples}\"\n",
    "    \n",
    "    model_inputs = tokenizer(inputs)\n",
    "    model_inputs['input_ids'] += [tokenizer.pad_token_id]\n",
    "    model_inputs[\"attention_mask\"] = [1] * len(model_inputs[\"input_ids\"])\n",
    "    \n",
    "    sample_input_ids = model_inputs[\"input_ids\"]\n",
    "    model_inputs[\"input_ids\"] = [tokenizer.pad_token_id] * (\n",
    "        max_length - len(sample_input_ids)\n",
    "    ) + sample_input_ids\n",
    "    model_inputs[\"attention_mask\"] = [0] * (max_length - len(sample_input_ids)) + model_inputs[\n",
    "        \"attention_mask\"\n",
    "    ]\n",
    "    model_inputs[\"input_ids\"] = torch.tensor(model_inputs[\"input_ids\"][:max_length])\n",
    "    model_inputs[\"attention_mask\"] = torch.tensor(model_inputs[\"attention_mask\"][:max_length])\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "/workspace/IE/venv/lib/python3.10/site-packages/peft/peft_model.py:1533: UserWarning: Position ids are not supported for parameter efficient tuning. Ignoring position ids.\n",
      "  warnings.warn(\"Position ids are not supported for parameter efficient tuning. Ignoring position ids.\")\n",
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (8192). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "for test_sample in test_dataset['text_content']:\n",
    "    test_sample = format(test_sample)\n",
    "    test_input = preprocess_for_inference(test_sample)\n",
    "    inputs = {k: v.unsqueeze(0).to(device) for k, v in test_input.items()}\n",
    "    prompt = inputs['input_ids'].shape[1]\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"], \n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_new_tokens=1024,\n",
    "            temperature=0.1\n",
    "        )\n",
    "    \n",
    "    result = tokenizer.decode(outputs[0, prompt:], skip_special_tokens=True)\n",
    "    with open(\"./model_outputs/my_model/\" + str(count) + \".txt\", 'w') as file:\n",
    "        file.write(result)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\summer_research\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "A matching Triton is not available, some optimizations will not be enabled\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\envs\\summer_research\\Lib\\site-packages\\xformers\\__init__.py\", line 57, in _is_triton_available\n",
      "    import triton  # noqa\n",
      "    ^^^^^^^^^^^^^\n",
      "ModuleNotFoundError: No module named 'triton'\n",
      "Some weights of the model checkpoint at infgrad/stella_en_400M_v5 were not used when initializing NewModel: ['new.pooler.dense.bias', 'new.pooler.dense.weight']\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"infgrad/stella_en_400M_v5\", trust_remote_code=True).cuda()\n",
    "\n",
    "def semantic_similarity(generated, truth):\n",
    "    global model\n",
    "    docs = [\n",
    "        generated,\n",
    "        truth\n",
    "    ]\n",
    "    doc_embeddings = model.encode(docs)\n",
    "    similarities = model.similarity(doc_embeddings, doc_embeddings)\n",
    "    return similarities[0][1].item()\n",
    "\n",
    "def structure_similarity(generated, truth):\n",
    "    keys1 = set(generated.keys())\n",
    "    keys2 = set(truth.keys())\n",
    "    intersection_keys = keys1.intersection(keys2)\n",
    "    union_keys = keys1.union(keys2)\n",
    "    if len(union_keys) == 0:\n",
    "        return 0\n",
    "    iou = len(intersection_keys) / len(union_keys)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the evaluation output format\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "columns = [\"API\", \"Endpoint_Name\", \"URL\", \"Semantic_Similarity:Name&Description\", \"Method\", \"Required_Param\", \"Optional_Param\", \"Notes\"]\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "def insert(api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes):\n",
    "    global df\n",
    "    df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
    "    df.index = df.index + 1\n",
    "    df = df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Filter and extract json only\n",
    "def clean_json(str):\n",
    "    json_str = str.strip()\n",
    "    start_index = json_str.find('{')\n",
    "    json_type = 'object' if start_index != -1 else 'array'\n",
    "    end_index = json_str.rfind('}') if json_type == 'object' else json_str.rfind(']')\n",
    "    if start_index == -1:\n",
    "        start_index = json_str.find('[')\n",
    "        if start_index == -1:\n",
    "            raise ValueError(\"No JSON object or array found in the text\")\n",
    "    if end_index == -1:\n",
    "        raise ValueError(\"Incomplete JSON structure, no closing bracket found\")\n",
    "        \n",
    "    return json_str[start_index:end_index+1]\n",
    "\n",
    "# Recursively search for a value in a nested JSON object and return the path\n",
    "def find_value_path(obj, value, path=None):\n",
    "    if path is None:\n",
    "        path = []\n",
    "    if isinstance(obj, dict):\n",
    "        for k, v in obj.items():\n",
    "            result = find_value_path(v, value, path + [k])\n",
    "            if result:\n",
    "                return result\n",
    "    elif isinstance(obj, list):\n",
    "        for i, item in enumerate(obj):\n",
    "            result = find_value_path(item, value, path + [i])\n",
    "            if result:\n",
    "                return result\n",
    "    else:\n",
    "        if obj == value:\n",
    "            return path\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_params(generated, truth):\n",
    "    num_params = len(truth)\n",
    "\n",
    "    if num_params == 0:\n",
    "        return 1.0\n",
    "    rate = 1 / num_params\n",
    "    score = 0\n",
    "\n",
    "    for param in truth:\n",
    "        truth_name = param['name'] \n",
    "        matching_param = next((param for param in generated if param['name'] == truth_name), None)\n",
    "        \n",
    "        if matching_param:\n",
    "            iou = structure_similarity(matching_param, param)\n",
    "            if iou == 1.0:\n",
    "                if param['type'] == matching_param['type']:\n",
    "                    score += rate * 0.5\n",
    "                score += rate * 0.5 * (semantic_similarity(matching_param['description'], param['description']))\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 completed!\n",
      "File 2 has an error: Expecting ',' delimiter: line 13 column 24 (char 427)\n",
      "3 completed!\n",
      "4 completed!\n",
      "5 completed!\n",
      "6 completed!\n",
      "File 7 has an error: Extra data: line 18 column 1 (char 396)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 completed!\n",
      "9 completed!\n",
      "10 completed!\n",
      "11 completed!\n",
      "12 completed!\n",
      "File 13 has an error: Expecting value: line 21 column 20 (char 876)\n",
      "14 completed!\n",
      "15 completed!\n",
      "16 completed!\n",
      "17 completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 completed!\n",
      "19 completed!\n",
      "20 completed!\n",
      "21 completed!\n",
      "File 22 has an error: Expecting value: line 42 column 33 (char 1464)\n",
      "23 completed!\n",
      "24 completed!\n",
      "File 25 has an error: No JSON object or array found in the text\n",
      "26 completed!\n",
      "27 completed!\n",
      "File 28 has an error: No JSON object or array found in the text\n",
      "File 29 has an error: Extra data: line 47 column 1 (char 1706)\n",
      "File 30 has an error: No JSON object or array found in the text\n",
      "31 completed!\n",
      "File 32 has an error: Expecting value: line 10 column 21 (char 224)\n",
      "33 completed!\n",
      "File 34 has an error: Expecting ',' delimiter: line 16 column 38 (char 634)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21944\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>API</th>\n",
       "      <th>Endpoint_Name</th>\n",
       "      <th>URL</th>\n",
       "      <th>Semantic_Similarity:Name&amp;Description</th>\n",
       "      <th>Method</th>\n",
       "      <th>Required_Param</th>\n",
       "      <th>Optional_Param</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>Convert JSON to JSONP</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This endpoint does not match its URL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>Generate Placeholder Text</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This endpoint does not match its URL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>Generate Chart</td>\n",
       "      <td>True</td>\n",
       "      <td>0.749484</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>List All Asteroids</td>\n",
       "      <td>True</td>\n",
       "      <td>0.863466</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>Get COVID-19 Cases for a Specific Country</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This endpoint does not match its URL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Contributors for Recipe</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This endpoint does not match its URL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Random Taco</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This endpoint does not match its URL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>3</td>\n",
       "      <td>Get Supported Color Name Lists</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IoU shows that the structure of this endpoint ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>3</td>\n",
       "      <td>Get Color Names</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This endpoint does not match its URL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1</td>\n",
       "      <td>Get IP Information</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IoU shows that the structure of this endpoint ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   API                              Endpoint_Name    URL  \\\n",
       "0   33                      Convert JSON to JSONP  False   \n",
       "1   31                  Generate Placeholder Text  False   \n",
       "2   27                             Generate Chart   True   \n",
       "3   26                         List All Asteroids   True   \n",
       "4   24  Get COVID-19 Cases for a Specific Country  False   \n",
       "..  ..                                        ...    ...   \n",
       "71   4                Get Contributors for Recipe  False   \n",
       "72   4                            Get Random Taco  False   \n",
       "73   3             Get Supported Color Name Lists   True   \n",
       "74   3                            Get Color Names  False   \n",
       "75   1                         Get IP Information   True   \n",
       "\n",
       "    Semantic_Similarity:Name&Description Method Required_Param  \\\n",
       "0                                    NaN   None           None   \n",
       "1                                    NaN   None           None   \n",
       "2                               0.749484  False              0   \n",
       "3                               0.863466   True            1.0   \n",
       "4                                    NaN   None           None   \n",
       "..                                   ...    ...            ...   \n",
       "71                                   NaN   None           None   \n",
       "72                                   NaN   None           None   \n",
       "73                                   NaN   None           None   \n",
       "74                                   NaN   None           None   \n",
       "75                                   NaN   None           None   \n",
       "\n",
       "    Optional_Param                                              Notes  \n",
       "0              NaN               This endpoint does not match its URL  \n",
       "1              NaN               This endpoint does not match its URL  \n",
       "2              0.0                                                     \n",
       "3              0.0                                                     \n",
       "4              NaN               This endpoint does not match its URL  \n",
       "..             ...                                                ...  \n",
       "71             NaN               This endpoint does not match its URL  \n",
       "72             NaN               This endpoint does not match its URL  \n",
       "73             NaN  IoU shows that the structure of this endpoint ...  \n",
       "74             NaN               This endpoint does not match its URL  \n",
       "75             NaN  IoU shows that the structure of this endpoint ...  \n",
       "\n",
       "[76 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_truths = test_dataset['json_form']\n",
    "for i in range(34):\n",
    "\n",
    "    # if i == 1:\n",
    "    #     break\n",
    "    \n",
    "    with open(\"./model_outputs/llama3_one_shot/\" + str(i + 1) + \".txt\", 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    try:\n",
    "        json_content = json.loads(clean_json(content))\n",
    "        truth = json.loads(json_truths[i])\n",
    "        if 'endpoints' in json_content:\n",
    "            endpoints = json_content['endpoints']\n",
    "            truth_endpoints = truth['endpoints']\n",
    "        else:\n",
    "            # The extraction does not have a good performance\n",
    "            insert(str(i + 1), None, None, None, None, None, None, \"Structure not matched\")\n",
    "            continue\n",
    "    except Exception as e:\n",
    "        print(\"File {} has an error: {}\".format(i+1, e))\n",
    "        continue\n",
    "    \n",
    "    for truth_endpoint in truth_endpoints:\n",
    "        truth_url = truth_endpoint['url']\n",
    "        path = find_value_path(endpoints, truth_url)\n",
    "        if path is not None:\n",
    "            endpoint = endpoints[path[0]]\n",
    "            for i in range(1, len(path) - 2):\n",
    "                endpoint = endpoint[path[i]]\n",
    "        else:\n",
    "            # url of one endpoint does not match\n",
    "            insert(str(i + 1), truth_endpoint['name'], False, None, None, None, None, \"This endpoint does not match its URL\")\n",
    "            continue\n",
    "        iou = structure_similarity(endpoint, truth_endpoint)\n",
    "        if iou == 1.0:\n",
    "            generated = endpoint['name'] + \": \" + endpoint['description']\n",
    "            ground_truth = truth_endpoint['name'] + \": \" + truth_endpoint['description']\n",
    "            similarity = semantic_similarity(generated, ground_truth)\n",
    "            method = endpoint['method'] == truth_endpoint['method']\n",
    "        else:\n",
    "            # IoU shows that the structure of this endpoint is not the same. Cannot do further actions.\n",
    "            insert(str(i + 1), truth_endpoint['name'], True, None, None, None, None, \"IoU shows that the structure of this endpoint is not the same.\")\n",
    "            continue\n",
    "        required_param_score = evaluate_params(endpoint['required_parameters'], truth_endpoint['required_parameters'])\n",
    "        optional_param_score = evaluate_params(endpoint['optional_parameters'], truth_endpoint['optional_parameters'])\n",
    "        # A complete evaluation\n",
    "        insert(str(i + 1), truth_endpoint['name'], True, similarity, method, required_param_score, optional_param_score, \"\")\n",
    "\n",
    "    print(str(i + 1) + \" completed!\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./results/llama3_one_shot_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summer_research",
   "language": "python",
   "name": "summer_research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
