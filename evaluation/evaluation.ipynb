{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a method to compare the similarity of the Json output between Llama 3, Llama 3 - one shot, GPT 3.5, and my model while dealing with API endpoints IE (information extraction) task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the same test/eval data while in training\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('billyfin/doc2json')\n",
    "# delete the last line for future one-shot test\n",
    "one_shot_example = dataset['train'][166]\n",
    "dataset = dataset.filter(lambda example, idx: idx != 166, with_indices=True)\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"title\": \"MyIP.com JSON API Documentation\",\n",
      "    \"endpoints\": [\n",
      "        {\n",
      "            \"name\": \"Get IP Information\",\n",
      "            \"description\": \"Retrieves information about the IP address making the request.\",\n",
      "            \"method\": \"GET\",\n",
      "            \"url\": \"https://api.myip.com\",\n",
      "            \"headers\": [],\n",
      "            \"required_parameters\": [],\n",
      "            \"optional_parameters\": []\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "JSON API | MyIP.com JSON API Contact JSON API You can make automated requests to the site using the API . Access URL: https://api.myip.com Response example: {\"ip\":\"66.249.75.9\",\"country\":\"United States\",\"cc\":\"US\"} Response elements: ip: IP address country: IP country location in English language cc: Two-letter country code in ISO 3166-1 alpha-2 format If there is no location data for an IP address cc will return \"XX\" and country \"Unknown\". Is this a free service? Yes. What are the API usage limits? There is no request limit, the only restriction is the server capacity which I will try to keep running smoothly. Can I use it for my commercial application? Yes, please give credit to myip.com if you can. How can I exclude some parameter(s) from the response? I will add that feature shortly, please check back for updates. I want you to add some feature, how can I contact you? If you have a suggestion please contact me here. MyIP.com 2024. × Contact For inquiries or feedback please get in touch at: OK\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset['json_form'][0])\n",
    "print(test_dataset['text_content'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df1b1ad062d4e7da77945e1e7bd9d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoModel, AutoTokenizer, default_data_collator, get_linear_schedule_with_warmup, BitsAndBytesConfig\n",
    "from huggingface_hub import notebook_login\n",
    "from peft import get_peft_config, get_peft_model, PromptTuningInit, PromptTuningConfig, TaskType, PeftType, PeftModel, PeftConfig\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "torch.manual_seed(42)\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 3 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc70d8cc6a940cd93c98f066cf2c9db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"quantization_config\": quantization_config},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "terminators = [\n",
    "    pipeline.tokenizer.eos_token_id,\n",
    "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "count = 1\n",
    "for test_sample in test_dataset['text_content']:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You will be given an API documentation. Extract the endpoints and output in JSON format.\"},\n",
    "        {\"role\": \"user\", \"content\": \"API text content: \" + test_sample + \"\\n\\nJson: \"},\n",
    "    ]\n",
    "    outputs = pipeline(\n",
    "        messages,\n",
    "        max_new_tokens=1024,\n",
    "        eos_token_id=terminators,\n",
    "        do_sample=True,\n",
    "        temperature=0.1,\n",
    "        return_full_text=False,\n",
    "    )\n",
    "    \n",
    "    result = outputs[0][\"generated_text\"]\n",
    "    with open(\"./model_outputs/llama3/\" + str(count) + \".txt\", 'w') as file:\n",
    "        file.write(result)\n",
    "    \n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 3 - one shot outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"quantization_config\": quantization_config},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "terminators = [\n",
    "    pipeline.tokenizer.eos_token_id,\n",
    "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "count = 1\n",
    "for test_sample in test_dataset['text_content']:\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": \"You will be given an API documentation. Extract the endpoints and output in JSON format.\\n\\nAPI text content: \" + one_shot_example['text_content'] + \"\\n\\nJson: \"},\n",
    "        {\"role\": \"assistant\", \"content\": one_shot_example['json_form']},\n",
    "        {\"role\": \"user\", \"content\": \"You will be given an API documentation. Extract the endpoints and output in JSON format.\\n\\nAPI text content: \" + test_sample + \"\\n\\nJson: \"},\n",
    "    ]\n",
    "    outputs = pipeline(\n",
    "        messages,\n",
    "        max_new_tokens=1024,\n",
    "        eos_token_id=terminators,\n",
    "        do_sample=True,\n",
    "        temperature=0.1,\n",
    "        return_full_text=False,\n",
    "    )\n",
    "    \n",
    "    result = outputs[0][\"generated_text\"]\n",
    "    with open(\"./model_outputs/llama3_one_shot/\" + str(count) + \".txt\", 'w') as file:\n",
    "        file.write(result)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT3.5 - one shot outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please type in your api key:  sk-None-LBwUJe7KgakZQCd1sFS2T3BlbkFJGZlBKtOqC13W19K504OG\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "OPENAI_API_KEY = str(input('Please type in your api key: '))\n",
    "\n",
    "count = 1\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "for test_sample in test_dataset['text_content']:\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        # model=\"gpt-4-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"You will be given an API documentation. Extract the endpoints and output in JSON format.\\n\\nAPI text content: \" + one_shot_example['text_content'] + \"\\n\\nJson: \"},\n",
    "            {\"role\": \"assistant\", \"content\": one_shot_example['json_form']},\n",
    "            {\"role\": \"user\", \"content\": \"You will be given an API documentation. Extract the endpoints and output in JSON format.\\n\\nAPI text content: \" + test_sample + \"\\n\\nJson: \"},\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    result = str(completion.choices[0].message.content)\n",
    "    with open(\"./model_outputs/gpt3.5_one_shot/\" + str(count) + \".txt\", 'w') as file:\n",
    "        file.write(result)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n",
      "Current CUDA Device: NVIDIA L40\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "    current_device = torch.cuda.current_device()\n",
    "    device_name = torch.cuda.get_device_name(current_device)\n",
    "    print(\"Current CUDA Device:\", device_name)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, using CPU instead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a75a2dcb0e7f40c4b2020fc60aa73e45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/585 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a375c334bc4bce9f7609f8096321a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6bb1f24452342b38b0abee42c50f38f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/328k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "peft_model_id = \"billyfin/llama_3_prompt_tuning_api2json_v4\"\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path,\n",
    "                                             quantization_config=quantization_config,\n",
    "                                             low_cpu_mem_usage=True,\n",
    "                                            )\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('meta-llama/Meta-Llama-3-8B-Instruct')\n",
    "\n",
    "# set pad_token_id equal to the eos_token_id if not set\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 10240\n",
    "\n",
    "def format(example):\n",
    "    input_messages = [\n",
    "        {\"role\":\"user\", \"content\": one_shot_example['text_content']},\n",
    "        {\"role\":\"assistant\", \"content\": one_shot_example['json_form']},\n",
    "        {\"role\":\"user\", \"content\": example},\n",
    "    ]\n",
    "    example = tokenizer.apply_chat_template(input_messages, tokenize=False) + \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
    "    return example\n",
    "    \n",
    "def preprocess_for_inference(examples):\n",
    "    inputs = f\"{examples}\"\n",
    "    \n",
    "    model_inputs = tokenizer(inputs)\n",
    "    model_inputs['input_ids'] += [tokenizer.pad_token_id]\n",
    "    model_inputs[\"attention_mask\"] = [1] * len(model_inputs[\"input_ids\"])\n",
    "    \n",
    "    sample_input_ids = model_inputs[\"input_ids\"]\n",
    "    model_inputs[\"input_ids\"] = [tokenizer.pad_token_id] * (\n",
    "        max_length - len(sample_input_ids)\n",
    "    ) + sample_input_ids\n",
    "    model_inputs[\"attention_mask\"] = [0] * (max_length - len(sample_input_ids)) + model_inputs[\n",
    "        \"attention_mask\"\n",
    "    ]\n",
    "    model_inputs[\"input_ids\"] = torch.tensor(model_inputs[\"input_ids\"][:max_length])\n",
    "    model_inputs[\"attention_mask\"] = torch.tensor(model_inputs[\"attention_mask\"][:max_length])\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "/workspace/IE/venv/lib/python3.10/site-packages/peft/peft_model.py:1533: UserWarning: Position ids are not supported for parameter efficient tuning. Ignoring position ids.\n",
      "  warnings.warn(\"Position ids are not supported for parameter efficient tuning. Ignoring position ids.\")\n",
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (8192). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "for test_sample in test_dataset['text_content']:\n",
    "    test_sample = format(test_sample)\n",
    "    test_input = preprocess_for_inference(test_sample)\n",
    "    inputs = {k: v.unsqueeze(0).to(device) for k, v in test_input.items()}\n",
    "    prompt = inputs['input_ids'].shape[1]\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"], \n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_new_tokens=1024,\n",
    "            temperature=0.1\n",
    "        )\n",
    "    \n",
    "    result = tokenizer.decode(outputs[0, prompt:], skip_special_tokens=True)\n",
    "    with open(\"./model_outputs/my_model/\" + str(count) + \".txt\", 'w') as file:\n",
    "        file.write(result)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\summer_research\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "D:\\Anaconda3\\envs\\summer_research\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "A matching Triton is not available, some optimizations will not be enabled\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\envs\\summer_research\\Lib\\site-packages\\xformers\\__init__.py\", line 57, in _is_triton_available\n",
      "    import triton  # noqa\n",
      "    ^^^^^^^^^^^^^\n",
      "ModuleNotFoundError: No module named 'triton'\n",
      "Some weights of the model checkpoint at infgrad/stella_en_400M_v5 were not used when initializing NewModel: ['new.pooler.dense.bias', 'new.pooler.dense.weight']\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"infgrad/stella_en_400M_v5\", trust_remote_code=True).cuda()\n",
    "\n",
    "def semantic_similarity(generated, truth):\n",
    "    global model\n",
    "    docs = [\n",
    "        generated,\n",
    "        truth\n",
    "    ]\n",
    "    doc_embeddings = model.encode(docs)\n",
    "    similarities = model.similarity(doc_embeddings, doc_embeddings)\n",
    "    return similarities[0][1].item()\n",
    "\n",
    "def structure_similarity(generated, truth):\n",
    "    keys1 = set(generated.keys())\n",
    "    keys2 = set(truth.keys())\n",
    "    intersection_keys = keys1.intersection(keys2)\n",
    "    union_keys = keys1.union(keys2)\n",
    "    if len(union_keys) == 0:\n",
    "        return 0\n",
    "    iou = len(intersection_keys) / len(union_keys)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the evaluation output format\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "columns = [\"API\", \"Endpoint_Name\", \"URL\", \"Semantic_Similarity:Name&Description\", \"Method\", \"Required_Param\", \"Optional_Param\", \"Notes\"]\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "def insert(api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes):\n",
    "    global df\n",
    "    df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
    "    df.index = df.index + 1\n",
    "    df = df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Filter and extract json only\n",
    "def clean_json(str):\n",
    "    json_str = str.strip()\n",
    "    start_index = json_str.find('{')\n",
    "    json_type = 'object' if start_index != -1 else 'array'\n",
    "    end_index = json_str.rfind('}') if json_type == 'object' else json_str.rfind(']')\n",
    "    if start_index == -1:\n",
    "        start_index = json_str.find('[')\n",
    "        if start_index == -1:\n",
    "            raise ValueError(\"No JSON object or array found in the text\")\n",
    "    if end_index == -1:\n",
    "        raise ValueError(\"Incomplete JSON structure, no closing bracket found\")\n",
    "        \n",
    "    return json_str[start_index:end_index+1]\n",
    "\n",
    "# Recursively search for a value in a nested JSON object and return the path\n",
    "def find_value_path(obj, value, path=None):\n",
    "    if path is None:\n",
    "        path = []\n",
    "    if isinstance(obj, dict):\n",
    "        for k, v in obj.items():\n",
    "            result = find_value_path(v, value, path + [k])\n",
    "            if result:\n",
    "                return result\n",
    "    elif isinstance(obj, list):\n",
    "        for i, item in enumerate(obj):\n",
    "            result = find_value_path(item, value, path + [i])\n",
    "            if result:\n",
    "                return result\n",
    "    else:\n",
    "        if obj == value:\n",
    "            return path\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_params(generated, truth):\n",
    "    num_params = len(truth)\n",
    "\n",
    "    if num_params == 0:\n",
    "        return 1.0\n",
    "    rate = 1 / num_params\n",
    "    score = 0\n",
    "\n",
    "    for param in truth:\n",
    "        truth_name = param['name'] \n",
    "        matching_param = next((param for param in generated if param['name'] == truth_name), None)\n",
    "        \n",
    "        if matching_param:\n",
    "            iou = structure_similarity(matching_param, param)\n",
    "            if iou == 1.0:\n",
    "                if param['type'] == matching_param['type']:\n",
    "                    score += rate * 0.5\n",
    "                score += rate * 0.5 * (semantic_similarity(matching_param['description'], param['description']))\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 completed!\n",
      "2 completed!\n",
      "3 completed!\n",
      "4 completed!\n",
      "5 completed!\n",
      "6 completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 completed!\n",
      "File 8 has an error: Expecting ',' delimiter: line 34 column 39 (char 1267)\n",
      "9 completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 completed!\n",
      "11 completed!\n",
      "12 completed!\n",
      "13 completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 completed!\n",
      "15 completed!\n",
      "16 completed!\n",
      "17 completed!\n",
      "18 completed!\n",
      "19 completed!\n",
      "20 completed!\n",
      "21 completed!\n",
      "22 completed!\n",
      "23 completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 completed!\n",
      "File 25 has an error: No JSON object or array found in the text\n",
      "26 completed!\n",
      "27 completed!\n",
      "28 completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 completed!\n",
      "30 completed!\n",
      "31 completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 completed!\n",
      "33 completed!\n",
      "34 completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_21604\\3863013164.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[-1] = [api, endpoint_name, url, similarity, method, requred_param_score, optional_param_score, notes]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>API</th>\n",
       "      <th>Endpoint_Name</th>\n",
       "      <th>URL</th>\n",
       "      <th>Semantic_Similarity:Name&amp;Description</th>\n",
       "      <th>Method</th>\n",
       "      <th>Required_Param</th>\n",
       "      <th>Optional_Param</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>Get Status Code Image</td>\n",
       "      <td>True</td>\n",
       "      <td>0.964871</td>\n",
       "      <td>True</td>\n",
       "      <td>0.941839</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>Convert JSON to JSONP</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This endpoint does not match its URL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>Get Multiple Memes from Subreddit</td>\n",
       "      <td>True</td>\n",
       "      <td>0.846215</td>\n",
       "      <td>True</td>\n",
       "      <td>0.967336</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>Get Meme from Subreddit</td>\n",
       "      <td>True</td>\n",
       "      <td>0.902386</td>\n",
       "      <td>True</td>\n",
       "      <td>0.975922</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>Get Multiple Memes</td>\n",
       "      <td>True</td>\n",
       "      <td>0.908097</td>\n",
       "      <td>True</td>\n",
       "      <td>0.958750</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2</td>\n",
       "      <td>Get Cat Facts in Different Language</td>\n",
       "      <td>True</td>\n",
       "      <td>0.854470</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2</td>\n",
       "      <td>Get Specific Cat Fact</td>\n",
       "      <td>True</td>\n",
       "      <td>0.840279</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2</td>\n",
       "      <td>Get Multiple Cat Facts</td>\n",
       "      <td>True</td>\n",
       "      <td>0.963473</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2</td>\n",
       "      <td>Get Random Cat Fact</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1</td>\n",
       "      <td>Get IP Information</td>\n",
       "      <td>True</td>\n",
       "      <td>0.846225</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   API                        Endpoint_Name    URL  \\\n",
       "0   34                Get Status Code Image   True   \n",
       "1   33                Convert JSON to JSONP  False   \n",
       "2   32    Get Multiple Memes from Subreddit   True   \n",
       "3   32              Get Meme from Subreddit   True   \n",
       "4   32                   Get Multiple Memes   True   \n",
       "..  ..                                  ...    ...   \n",
       "94   2  Get Cat Facts in Different Language   True   \n",
       "95   2                Get Specific Cat Fact   True   \n",
       "96   2               Get Multiple Cat Facts   True   \n",
       "97   2                  Get Random Cat Fact   True   \n",
       "98   1                   Get IP Information   True   \n",
       "\n",
       "    Semantic_Similarity:Name&Description Method  Required_Param  \\\n",
       "0                               0.964871   True        0.941839   \n",
       "1                                    NaN   None             NaN   \n",
       "2                               0.846215   True        0.967336   \n",
       "3                               0.902386   True        0.975922   \n",
       "4                               0.908097   True        0.958750   \n",
       "..                                   ...    ...             ...   \n",
       "94                              0.854470   True        1.000000   \n",
       "95                              0.840279   True        1.000000   \n",
       "96                              0.963473   True        1.000000   \n",
       "97                              1.000000   True        1.000000   \n",
       "98                              0.846225   True        1.000000   \n",
       "\n",
       "    Optional_Param                                 Notes  \n",
       "0              1.0                                        \n",
       "1              NaN  This endpoint does not match its URL  \n",
       "2              1.0                                        \n",
       "3              1.0                                        \n",
       "4              1.0                                        \n",
       "..             ...                                   ...  \n",
       "94             0.0                                        \n",
       "95             0.0                                        \n",
       "96             0.0                                        \n",
       "97             1.0                                        \n",
       "98             1.0                                        \n",
       "\n",
       "[99 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_truths = test_dataset['json_form']\n",
    "for i in range(34):\n",
    "\n",
    "    # if i == 1:\n",
    "    #     break\n",
    "    \n",
    "    with open(\"./model_outputs/my_model/\" + str(i + 1) + \".txt\", 'r') as file:\n",
    "        content = file.read()\n",
    "    try:\n",
    "        json_content = json.loads(clean_json(content))\n",
    "        truth = json.loads(json_truths[i])\n",
    "        if 'endpoints' in json_content:\n",
    "            endpoints = json_content['endpoints']\n",
    "            truth_endpoints = truth['endpoints']\n",
    "        else:\n",
    "            # The extraction does not have a good performance\n",
    "            insert(str(i + 1), None, None, None, None, None, None, \"Structure not matched\")\n",
    "            continue\n",
    "    except Exception as e:\n",
    "        print(\"File {} has an error: {}\".format(i+1, e))\n",
    "        continue\n",
    "    \n",
    "    for truth_endpoint in truth_endpoints:\n",
    "        truth_url = truth_endpoint['url']\n",
    "        path = find_value_path(endpoints, truth_url)\n",
    "        if path is not None:\n",
    "            endpoint = endpoints[path[0]]\n",
    "            for i in range(1, len(path) - 2):\n",
    "                endpoint = endpoint[path[i]]\n",
    "        else:\n",
    "            # url of one endpoint does not match\n",
    "            insert(str(i + 1), truth_endpoint['name'], False, None, None, None, None, \"This endpoint does not match its URL\")\n",
    "            continue\n",
    "        iou = structure_similarity(endpoint, truth_endpoint)\n",
    "        if iou == 1.0:\n",
    "            generated = endpoint['name'] + \": \" + endpoint['description']\n",
    "            ground_truth = truth_endpoint['name'] + \": \" + truth_endpoint['description']\n",
    "            similarity = semantic_similarity(generated, ground_truth)\n",
    "            method = endpoint['method'] == truth_endpoint['method']\n",
    "        else:\n",
    "            # IoU shows that the structure of this endpoint is not the same. Cannot do further actions.\n",
    "            insert(str(i + 1), truth_endpoint['name'], True, None, None, None, None, \"IoU shows that the structure of this endpoint is not the same.\")\n",
    "            continue\n",
    "        required_param_score = evaluate_params(endpoint['required_parameters'], truth_endpoint['required_parameters'])\n",
    "        optional_param_score = evaluate_params(endpoint['optional_parameters'], truth_endpoint['optional_parameters'])\n",
    "        # A complete evaluation\n",
    "        insert(str(i + 1), truth_endpoint['name'], True, similarity, method, required_param_score, optional_param_score, \"\")\n",
    "\n",
    "    print(str(i + 1) + \" completed!\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./results/my_model_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summer_research",
   "language": "python",
   "name": "summer_research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
